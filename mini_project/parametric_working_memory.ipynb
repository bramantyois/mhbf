{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "\r\n",
                "import numpy as np\r\n",
                "import torch\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "import seaborn as sns"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "max_t = 75\r\n",
                "\r\n",
                "np.random.seed(5)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "def input_to_tensor(u):\r\n",
                "    s = u.reshape(u.shape[0], u.shape[1], 1)\r\n",
                "    return torch.from_numpy(s)\r\n",
                "\r\n",
                "def output_to_tensor(y, time_steps=1):\r\n",
                "    y_ = np.ones()\r\n",
                "\r\n",
                "    return torch.from_numpy(y.reshape(-1,time_steps))   \r\n",
                "\r\n",
                "def random_shuffle(dataset, batch_size):\r\n",
                "    n_trial = dataset['y'].shape[0]\r\n",
                "\r\n",
                "    perm = np.random.permutation(n_trial)\r\n",
                "    \r\n",
                "    num_batch = n_trial // batch_size\r\n",
                "\r\n",
                "    in_list = []\r\n",
                "    out_list = []\r\n",
                "\r\n",
                "    for i in range(num_batch):\r\n",
                "        idx = perm[i*batch_size:(i+1)*batch_size]\r\n",
                "\r\n",
                "        us = dataset['u'][:,idx]\r\n",
                "        ys = dataset['y'][idx].astype(np.float32)\r\n",
                "\r\n",
                "        in_list.append(us.copy())\r\n",
                "        out_list.append(ys.copy())\r\n",
                "\r\n",
                "    return num_batch, in_list, out_list"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "def generate_dataset_2(num_trial, t=75, delay = 50):\r\n",
                "    set = [10,14,18,22,26,30,34]\r\n",
                "\r\n",
                "    f_min = 10\r\n",
                "    f_max = 34\r\n",
                "    \r\n",
                "    f1 = np.random.choice(set, size=num_trial)\r\n",
                "    f2 = np.random.choice(set, size=num_trial)\r\n",
                "    \r\n",
                "    u1 = (1 / (f_max - f_min))*(f1 - 0.5*(f_max + f_min))\r\n",
                "    u2 = (1 / (f_max - f_min))*(f2 - 0.5*(f_max + f_min))\r\n",
                "\r\n",
                "    u = np.zeros((t, num_trial))\r\n",
                "\r\n",
                "    win1 = [5, 10]\r\n",
                "    win2 = [win1[1] + delay, win1[1]+ delay + 10]\r\n",
                "\r\n",
                "    for i in range(num_trial):\r\n",
                "        u[win1[0]:win1[1], i] = u1[i]\r\n",
                "        u[win2[0]:win2[1], i] = u2[i]\r\n",
                "\r\n",
                "    y = (f1 - f2)/ (f_max-f_min)\r\n",
                "    \r\n",
                "\r\n",
                "    r_dict = {'u':u.astype(np.float32), 'y':y.astype(np.float32)}    \r\n",
                "    return r_dict"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "class LowRankRNN2(torch.nn.Module):\r\n",
                "    def __init__(self, N, del_t, tau, rank=2):\r\n",
                "        super(LowRankRNN2, self).__init__()\r\n",
                "\r\n",
                "        self.m1 = torch.nn.Parameter(torch.normal(0, 0.05, (N, rank)))\r\n",
                "        self.m2 = torch.nn.Parameter(torch.normal(0, 0.05, (N, rank)))\r\n",
                "        \r\n",
                "        self.n1 = torch.nn.Parameter(torch.normal(0, 0.05, (rank, N)))\r\n",
                "        self.n2 = torch.nn.Parameter(torch.normal(0, 0.05, (rank, N)))\r\n",
                "        \r\n",
                "        #self.ms = []\r\n",
                "        #self.ns = []\r\n",
                "\r\n",
                "        ##for i in range(rank):\r\n",
                "        #   self.ms.append(torch.nn.Parameter(torch.normal(0, 0.05, (N, 1))))\r\n",
                "        #   self.ns.append(torch.nn.Parameter(torch.normal(0, 0.05, (1, N))))\r\n",
                "\r\n",
                "        self.I = torch.nn.Parameter(torch.normal(0, 0.05, (1, N)))\r\n",
                "        self.w = torch.nn.Parameter(torch.normal(0, 0.05, (N, 1)))\r\n",
                "\r\n",
                "        # self.j = torch.nn.Parameter(torch.normal(0, 0.05, (N, N)))\r\n",
                "        # self.j.requires_grad = True\r\n",
                "\r\n",
                "        self.time_mul = del_t / tau\r\n",
                "\r\n",
                "        self.N = N\r\n",
                "\r\n",
                "\r\n",
                "    def forward(self, u, x): # u->(batch, 1), x->(batch, N) \r\n",
                "\r\n",
                "        # print(j)\r\n",
                "        # for i in range(self.rank):\r\n",
                "        #     j = torch.add(j, torch.mm(self.ms[i], self.ns[i]))\r\n",
                "        #     print(j)\r\n",
                "        \r\n",
                "        j1 = torch.mm(self.m1, self.n1)\r\n",
                "        j2 = torch.mm(self.m2, self.n2)\r\n",
                "\r\n",
                "        j = torch.add(j1, j2)\r\n",
                "        j = torch.div(j, 2*self.N)\r\n",
                "\r\n",
                "        a = torch.tanh(x)\r\n",
                "        a = torch.matmul(a, j) # -> (batch, N)\r\n",
                "\r\n",
                "        # a = torch.tanh(x_t)\r\n",
                "        # a = torch.matmul(self.j, a) # -> (N, batch)\r\n",
                "\r\n",
                "        b = torch.mm(u, self.I) # -> (batch, N)\r\n",
                "\r\n",
                "        c = torch.add(a, b)\r\n",
                "        c = torch.sub(c, x)\r\n",
                "        c = torch.mul(c, self.time_mul)\r\n",
                "\r\n",
                "        xx = torch.add(x, c) # -> (batch, N)\r\n",
                "        \r\n",
                "        out = torch.mm(xx, self.w) #->(batch, 1)\r\n",
                "        out  = torch.div(out, self.N)\r\n",
                "        return out, xx\r\n",
                "\r\n",
                "    def init_x(self, batch_size=16):\r\n",
                "        return torch.normal(0, 0.05, (batch_size, self.N))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "source": [
                "def training2(lr=5e-3, num_epochs=10, n_trial = 16, batch_size=8, N=128, T=5, t_step=max_t, min_delay=25, max_delay=50):\r\n",
                "    # Low rank RNN params\r\n",
                "    tau = 100e-3\r\n",
                "    del_t = 20e-3\r\n",
                "\r\n",
                "    # Autograd Params\r\n",
                "    lr = 5e-3\r\n",
                "    rnn = LowRankRNN2(N, del_t, tau, 1)\r\n",
                "\r\n",
                "    m = torch.nn.Sigmoid()\r\n",
                "\r\n",
                "    criterion = torch.nn.MSELoss()\r\n",
                "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\r\n",
                "\r\n",
                "    delays = np.arange(min_delay, max_delay, step=1)\r\n",
                "\r\n",
                "    datasets = []\r\n",
                "    for delay in (delays):\r\n",
                "        datasets.append(generate_dataset_2(num_trial=n_trial, t=t_step,delay=delay))\r\n",
                "        \r\n",
                "    loss_log = []\r\n",
                "    for dataset in datasets:\r\n",
                "        for epoch in range(num_epochs):\r\n",
                "            num_batch, in_list, out_list = random_shuffle(dataset, batch_size)\r\n",
                "\r\n",
                "            for i in range(num_batch):\r\n",
                "                x_past = rnn.init_x(batch_size)\r\n",
                "                in_tensor = input_to_tensor(in_list[i])\r\n",
                "                out_tensor = output_to_tensor(out_list[i])\r\n",
                "                \r\n",
                "                outs = []\r\n",
                "                loss_sum = 0\r\n",
                "                for j in range(t_step):\r\n",
                "                    out, x_past = rnn(in_tensor[j,:,:], x_past)\r\n",
                "                    outs.append(out)\r\n",
                "\r\n",
                "                    # if j >= (t_step - T):\r\n",
                "                    #     loss = criterion(out, out_tensor)\r\n",
                "                    #     optimizer.zero_grad()\r\n",
                "                    #     loss.backward(retain_graph=True)\r\n",
                "                    #     optimizer.step()\r\n",
                "                    #     loss_sum  += loss.item()\r\n",
                "\r\n",
                "                # loss_sum = 0\r\n",
                "\r\n",
                "                for j in range(-5, 0):    \r\n",
                "                    loss = criterion(outs[j], out_tensor)  \r\n",
                "                    optimizer.zero_grad()              \r\n",
                "                    loss.backward(retain_graph=True)\r\n",
                "                    optimizer.step()\r\n",
                "                    loss_sum  += loss.item()\r\n",
                "                \r\n",
                "                loss_log.append(loss_sum/(T))\r\n",
                "\r\n",
                "            # loss = criterion(outs[j], out_tensor)\r\n",
                "            # optimizer.zero_grad()\r\n",
                "            # loss.backward()\r\n",
                "            # optimizer.step()\r\n",
                "            # loss_log.append(loss.item())\r\n",
                "           \r\n",
                "            if epoch % int(num_epochs*0.1) == 0:\r\n",
                "                print('loss: {}'.format(loss_log[-1]))\r\n",
                "            # if loss_log[-1]<5e-2:\r\n",
                "            #    break\r\n",
                "\r\n",
                "    return rnn\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "source": [
                "rnn2 = training2(n_trial=256, batch_size=32, num_epochs=200, min_delay=50, max_delay=51)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "loss: 0.16956888735294343\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-160-2bd172d1c681>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m<ipython-input-141-6a0634d7a2fa>\u001b[0m in \u001b[0;36mtraining2\u001b[1;34m(lr, num_epochs, n_trial, batch_size, N, T, t_step, min_delay, max_delay)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mloss_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_past\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_past\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[0mouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m<ipython-input-13-82266725655b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, u, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#     print(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mj1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mj2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "source": [
                "dataset = generate_dataset_2(num_trial=1)\r\n",
                "num_batch, in_list, out_list = random_shuffle(dataset, 1)\r\n",
                "x_past = rnn2.init_x(1)\r\n",
                "outs = []\r\n",
                "for i in range(max_t):\r\n",
                "    in_tensor = torch.from_numpy(dataset['u'][i].reshape(1,1))\r\n",
                "    out, x_past = rnn2.forward(in_tensor, x_past)\r\n",
                "    outs.append(out.detach().numpy())\r\n",
                "\r\n",
                "outs= np.array(outs).ravel()\r\n",
                "\r\n",
                "plt.plot(outs)\r\n",
                "plt.axhline(dataset['y'][0], color='red')\r\n",
                "plt.plot(dataset['u'])\r\n",
                "\r\n",
                "plt.show()"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdhklEQVR4nO3dfZBU9Z3v8fe3u2d4GFFAhgeZ4UElIPEBcURN1BUNBs0maB4xWZdNmVDZK5U1tUkuqc3m5tZNZVO52ZvNVoxe4nU1u1FjjA+soUIMG2MejDIoCkiQkaAMDDCAiDDAPH3vH316aMYeGKbPzDlnzudV1fZ57P4ySH/mfM/p3zF3R0RE0isTdQEiIhItBYGISMopCEREUk5BICKScgoCEZGUy0VdQF+MGTPGp0yZEnUZIiKJsmbNmj3uXt19eSKDYMqUKdTX10ddhohIopjZ66WWqzUkIpJyCgIRkZRTEIiIpJyCQEQk5RQEIiIppyAQEUk5BYGISMol8nsEIiLH2fIb2Pq7qKt4p3e9H2rqoq7ipBQEIpJ8v/wH2LkOsKgrKeKwfQ3c+mjUhZyUgkBEku/oQbjgY/CRe6Ku5Jj7PwStB6Ouold0jkBEkq/tMFQMi7qK41UMh7aWqKvoFQWBiCRfWwtUVEVdxfEqh0OrgkBEpP+5Q+uh/AdvnOiIQERkgHS0gXeoNVQGBYGIJFvbofyzWkN9FkoQmNl8M9tkZg1mtrTE+hlm9qyZHTWzL3Zbt9XM1pnZWjPTTQZE5NS0Hc4/x+6IoAo62/JHLDFX9uWjZpYF7gTmAY3AajNb7u6vFG22D/g8cFMPLzPX3feUW4uIpFDht+7KmB0RFIKprQWyZ0Rby0mEcUQwB2hw9y3u3go8BCwo3sDdd7v7aiD+0SgiydLVGorZyeLCyesEtIfCCIKJwLai+cZgWW858EszW2Nmi3vayMwWm1m9mdU3Nzf3sVQRGXTi3BqCRJwwDiMISn2n209h//e6+2zgBuB2M7u61Ebuvszd69y9rrr6HfdeFpG0ag2OCOLcGoq5MIKgEagtmq8BdvR2Z3ffETzvBh4j32oSEemdwgetWkN9FkYQrAammdlUM6sEFgLLe7OjmVWZ2YjCNHA9sD6EmkQkLbpaQzELgq7W0KFo6+iFsq8acvd2M1sCrASywL3uvsHMPhesv9vMxgP1wOlAp5ndAcwExgCPmVmhlgfc/Rfl1iQiKdLVGopbEBRaQ4ejraMXQhl91N1XACu6Lbu7aHon+ZZRdweAi8KoQURSKratoeCIICWtIRGR6MQ1CFJ2slhEJDqtLZDJQa4y6kqOVwgmBYGISD+L4xDUUNQaiv/JYgWBiCRbW0v8vkwGkK0EyyTiZLGCQESSrbUlflcMAZjlj1TUGhIR6WdxbQ1BMBS1WkMiIv0rrq0hyNel1pCISD+La2sI1BoSERkQag2VTUEgIsmm1lDZFAQikmyxbw3piEBEpH+1HY7f8BIFCbmBvYJARJKt7VB8g0CtIRGRftbeCp3tag2VSUEgIskV15FHC9QaEhHpZ3EPgorh0NkGHW1RV3JCCgIRSa7Cb9txu3F9QUKGolYQiEhydR0RxPR7BAm5gb2CQESSKwmtIdARgYhIv+m6cb1aQ+VQEIhIchWu0VdrqCyhBIGZzTezTWbWYGZLS6yfYWbPmtlRM/viqewrItKjrtaQjgjKUXYQmFkWuBO4AZgJ3GJmM7tttg/4PPCdPuwrIlJaV2tI5wjKEcYRwRygwd23uHsr8BCwoHgDd9/t7quB7hfTnnRfEZEexb41VLiB/eAPgonAtqL5xmBZqPua2WIzqzez+ubm5j4VKiKDTGH4hti2hoKASsERgZVY5mHv6+7L3L3O3euqq6t7XZyIDGKtLZDJQa4y6kpKS1FrqBGoLZqvAXYMwL4iknZxHoIailpD8R54LowgWA1MM7OpZlYJLASWD8C+IpJ2cR6CGiBbCZaJ/VDUuXJfwN3bzWwJsBLIAve6+wYz+1yw/m4zGw/UA6cDnWZ2BzDT3Q+U2rfcmkQkJeJ8dzIAs0TcwL7sIABw9xXAim7L7i6a3km+7dOrfUVEeiXurSFIxA3s9c1iEUmuuLeGIBF3KVMQiEhytR2Od2sIEtEaUhCISHK1tsT/iECtIRGRfqTWUCgUBCKSXG2H4zu8REECbmCvIBCR5Gptie+9CAoScAN7BYGIJJdaQ6FQEIhIMnW0QWd7AoJArSERkf4R93sRFKg1JCLST+J+4/qCiuHQ2ZY/gokpBYGIJFPXTWkSEAQQ6y+VKQhEJJmS1BqCWLeHFAQikkxJag2BjghEREKnIAiNgkBEkqnQalFrqGwKAhFJpq4jgph/s1hHBCIi/aQrCOI+1pCCQESkfySmNVS4gb2CQEQkXIVhG2LfGgqOWHREICISsrbDYFnIVkRdyYmlpTVkZvPNbJOZNZjZ0hLrzcz+NVj/spnNLlq31czWmdlaM6sPox4RSYHCENRmUVdyYl2tofgOPJcr9wXMLAvcCcwDGoHVZrbc3V8p2uwGYFrwuAy4K3gumOvue8qtRURSpC0Bt6kEyFaCZWI9FHUYRwRzgAZ33+LurcBDwIJu2ywAfuR5fwRGmtmEEN5bRNKqrSX+VwxB/ogl5jewDyMIJgLbiuYbg2W93caBX5rZGjNb3NObmNliM6s3s/rm5uYQyhaRREvC3ckKYn4D+zCCoFSDzk9hm/e6+2zy7aPbzezqUm/i7svcvc7d66qrq/terYgMDkk5IoDY36UsjCBoBGqL5muAHb3dxt0Lz7uBx8i3mkRETiwp5wggFa2h1cA0M5tqZpXAQmB5t22WA38dXD10OfCWuzeZWZWZjQAwsyrgemB9CDWJyGCXpNZQxbBYB0HZVw25e7uZLQFWAlngXnffYGafC9bfDawAbgQagBbg08Hu44DHLH/5Vw54wN1/UW5NIpICSWoNxfx2lWUHAYC7ryD/YV+87O6iaQduL7HfFuCiMGoQkZRJWmvo8JtRV9EjfbNYRJIpca2hwX2yWERk4Kk1FBoFgYgkT0cbdLbFf8C5goqqY4PkxZCCQESSJyk3ri9Qa0hEJGSFD9XEtIaqoKMVOtqjrqQkBYGIJE9SblNZ0DUUdTzbQwoCEUmeJLaGILbtIQWBiCRPEltDENuB5xQEIpI8SblNZUHM71KmIBCR5EnKjesLuoJArSERkXB0tYYSEgSFwFJrSEQkJF2toYQEgVpDIiIhKxwRqDUUCgWBiCRPa8KOCNQaEhEJWVsLWBaylVFX0jtqDYmIhKztcP7D1UrdDj2GFAQiIiFrPZSc8wMAuSFgmdgORa0gEJHkSdLdySB/5BLjG9grCEQkeQqtoSSJ8Q3sFQQikjxJaw1BrO9SpiAQkeRJWmsIYt0ayoXxImY2H/gekAXucfdvdVtvwfobgRbgb9z9hd7smwTuTmtHJ0daOznS3kFreyed7nR0Op3uAJgZGTMMyGaMXNbIZoyKTIZc1qjMZajIZMhkEnIVhEiU2lpg2Oioqzg1MW4NlR0EZpYF7gTmAY3AajNb7u6vFG12AzAteFwG3AVc1st9I7X34FG27j3EG/taeH1vC9v2HWbvoaO8eaiVfS2t7D/UxqHWdjo9nPfLZfKhUJnLUJnNPw/JZajMZYPn/Pyx6WzXdpW5DBXF+2QzVGSNylw2eM6vr8jmw6cik1+fC7bLFc3nisIql8kEz/n5bMbImim0JDqtLWoNhSiMI4I5QIO7bwEws4eABUDxh/kC4Efu7sAfzWykmU0ApvRi3/CsuQ8aVvW4utNh/+FW9re05R+HWznS1gnAEGA6cGEuw5CKbPCBa1SOypALfpPPf0Dmf/s3A8OOu8w5f3DguIMDnZ6f7nSn0/NHFoXpTnc6O49Ndxx1Oo8Utj1+XWdnt/1OEkptwSOML7sXssCCox0MjOP/7IWfxbHpY9t1remaP7bPsb0KC49tY90XcPz+x16jOyv67zt36ku0hX0pu/WpinQ5v6WRzRXnU7XnEFPGJGUo6ipoegl+cmt5r3P1F2HCReHUFAgjCCYC24rmG8n/1n+ybSb2cl8AzGwxsBhg0qRJfav0YDPs2Xzcok6clqMdHDzazsGj7XQEn6Ijs8b4iixDh2W7fjvPZY3Mif6RevDoC6Nvn0I9lnEscDyYyE8fvw73ouXBthzbtji4KF4WbFT8xz1u3XHLuv1YvPQ2nGhZUV09/ZlPvKCvfzVeei6kI0Dpm0Ybz53bJrPiO09zYc0ZfOiis/jI7BpGVcX4m8bvej+8ufUdn0GnrB+OKsIIglIfX93/mfS0TW/2zS90XwYsA6irq+vbP8O/+FL+AezYf5hlz2zhkTWNHDzazoihOeadN47r3z2eS6eM4szThvTpLeIgxEwRia1/fOswF7/UxPKXdvCNn2/k4fptLF9yJUMrslGXVlrdp/OPGAojCBqB2qL5GmBHL7ep7MW+odq65xB3Pf0aj77YiDt88KKzWDDrLN5zzhgqc7qISiQpJpwxjM9efTafvfpsVm3cxW331/PtX2ziax+cGXVpiRNGEKwGppnZVGA7sBD4ZLdtlgNLgnMAlwFvuXuTmTX3Yt/Q/O+Vf+Kup18jl81wy5xJLL76bGpGJeyEk4i8w3XnjWPRFZO59/d/5toZY7ly2pioS0qUsoPA3dvNbAmwkvwloPe6+wYz+1yw/m5gBflLRxvIXz766RPtW25NPTlvwul89qqzue2qqYwdMbS/3kZEIrD0hvP4XcMe/v6na1l5x9WMHB7j8wUxY17qTF3M1dXVeX19fdRliEjMrN/+Fjfd+Xvef/54vn/LxVhSRicdIGa2xt3rui9XU1xEBo3zJ57BF+a9i5+/3MTja7dHXU5iKAhEZFD53F+cwyWTR/GNJzdyuLUj6nISQUEgIoNKNmMsvWEGew+18uDzb0RdTiIoCERk0Ll0ymgumzqa//vMaxxt11HBySgIRGRQWnLtuew6cJSfrdG5gpNREIjIoHTluWO4qHYkd/2mgfaOzqjLiTUFgYgMSmbGkrnnsm3fYZa/1K8DFiSegkBEBq3rZoxlxvgR/ODp1+gMa6z4QUhBICKDViZj3D73XBp2H2Tlhp1RlxNbCgIRGdRuvGACZ4+p4vu/biCJIykMBAWBiAxq2YzxmavOZsOOA7zwxptRlxNLCgIRGfRuuvgsRgzJ8e/Pvh51KbGkIBCRQW94ZY6PXFLDinU72XPwaNTlxI6CQERS4a8un0RrRycP1287+cYpoyAQkVQ4d+wIrjj7TB547o2ue5NLnoJARFLj1ism0/jmYX7z6u6oS4kVBYGIpMa8meMYO2KIThp3oyAQkdSoyGZYOGcST7/azLZ9LVGXExsKAhFJlVvm1JIx48fP6V4FBQoCEUmVCWcMY95543i4fpvuVRBQEIhI6nzysknsO9TKU6/sirqUWCgrCMxstJk9ZWabg+dRPWw338w2mVmDmS0tWv51M9tuZmuDx43l1CMi0htXnjuGiSOH8ZPV+k4BlH9EsBRY5e7TgFXB/HHMLAvcCdwAzARuMbOZRZt8191nBY8VZdYjInJSmYzxsboaftewRyeNKT8IFgD3B9P3AzeV2GYO0ODuW9y9FXgo2E9EJDIfq6sF4KdrGiOuJHrlBsE4d28CCJ7HlthmIlB8/NUYLCtYYmYvm9m9PbWWAMxssZnVm1l9c3NzmWWLSNpNHDmMq6ZV80j9ttR/0/ikQWBmvzKz9SUevf2t3kosK/zU7wLOAWYBTcA/9/Qi7r7M3evcva66urqXby0i0rNP1NWy460j/HZzun+5zJ1sA3d/X0/rzGyXmU1w9yYzmwCU+t52I1BbNF8D7Aheu+uUvZn9EHiyt4WLiJTrfTPHMrqqkofrt3HN9FINjXQotzW0HFgUTC8CniixzWpgmplNNbNKYGGwH0F4FNwMrC+zHhGRXhuSy3LzxRN56pVd7E3x8NTlBsG3gHlmthmYF8xjZmeZ2QoAd28HlgArgY3Aw+6+Idj/22a2zsxeBuYCXyizHhGRU/KJS2tp63Aee3F71KVExpJ4D8+6ujqvr6+PugwRGSRu/sHveftIO0994WrMSp3WHBzMbI2713Vfrm8Wi0jqLby0lobdB3nhjf1RlxIJBYGIpN4HLjyL4ZVZfprSu5cpCEQk9U4bkuMDF0zgP1/aQUtre9TlDDgFgYgI8PFLaznU2sGKdTujLmXAKQhERIC6yaOYOqaKh1M4EJ2CQEQEMMsPRPf81n1saT4YdTkDSkEgIhL46OwashnjkZQNRKcgEBEJjD19KNe8q5qfvdBIe0dn1OUMGAWBiEiRj9XVsuvAUZ5J0UB0CgIRkSLXnTeWMadV8vDq9LSHFAQiIkUqshluvngiv9q4iz0pGYhOQSAi0s3H62pp73QeT8lAdAoCEZFupo0bwexJI3lo9TaSODDnqVIQiIiUsPDSScFAdG9GXUq/UxCIiJTwgQsnUFWZ5aHnB/83jRUEIiIlVA3J8cGLzuLJl5t4+0hb1OX0KwWBiEgPPnFpLYfbOnjy5aaoS+lXCgIRkR7Mqh3J9HEjeGiQD0SnIBAR6YGZ8YlLa3lp2342Nh2Iupx+oyAQETmBmy+eSGU2w08G8VFBWUFgZqPN7Ckz2xw8j+phu3vNbLeZre/L/iIiURlVVcn17x7H42u3c6StI+py+kW5RwRLgVXuPg1YFcyXch8wv4z9RUQis/DSSexvaWPlhsF597Jyg2ABcH8wfT9wU6mN3P0ZYF9f9xcRidJ7zjmTSaOH88Bzb0RdSr8oNwjGuXsTQPA8tr/2N7PFZlZvZvXNzekZHlZEopfJGAvn1PLcn/fRsHvw3b3spEFgZr8ys/UlHgsGosACd1/m7nXuXlddXT2Qby0iwscuqaUiazz4/OA7KsidbAN3f19P68xsl5lNcPcmM5sA7D7F9y93fxGRAVE9YgjXv3s8j6xp5Evvn87QimzUJYWm3NbQcmBRML0IeGKA9xcRGTCfmjOJtw63sWLd4PqmcblB8C1gnpltBuYF85jZWWa2orCRmT0IPAtMN7NGM7vtRPuLiMTRFeecydQxVYPupPFJW0Mn4u57getKLN8B3Fg0f8up7C8iEkdmxi1zavnmij+xaefbTB8/IuqSQqFvFouInIKPXlJLZTbDA8+9HnUpoVEQiIicgtFVldxwwXgefXE7h1sHxzeNFQQiIqfok3Mm8faRdv7zpR1RlxIKBYGIyCmaM3U008aexo/+uHVQ3NNYQSAicorMjL9+zxTWbz/Ai9v2R11O2RQEIiJ98OGLJzJiSI4f/WFr1KWUTUEgItIHVUNyfOSSGn6+ronmt49GXU5ZFAQiIn106xWTaevwxI8/pCAQEemjc6pP46ppY/jxc6/T1tEZdTl9piAQESnDoiumsOvAUX65YVfUpfSZgkBEpAxzZ4ylZtQw7n92a9Sl9JmCQESkDNmMcevlk3n+z/vY2HQg6nL6REEgIlKmj9fVMiSX4f6EXkqqIBARKdOoqko+PLuGR1/czt6DybuUVEEgIhKC266cQmt7J//xx+RdSqogEBEJwbljRzB3ejX//setHGlL1qikCgIRkZB85qqz2XOwleVrkzUqqYJARCQk7znnTGaMH8E9v9sS+qikR9o6+PryDex++0iorwsKAhGR0JgZn7nqbF7ddZDfbt4T6mt/96lXue8PW9m862CorwsKAhGRUH3woglUjxjCPb/7c2ivuXbbfn742y3cMqeW9547JrTXLVAQiIiEaEguy6IrJvPMq81s2vl22a93tL2DLz/yEuNOH8pXbjwvhArfqawgMLPRZvaUmW0Onkf1sN29ZrbbzNZ3W/51M9tuZmuDx43l1CMiEgefumwyQysyLHtmS9mvded/NfDqroN88+YLOH1oRQjVvVO5RwRLgVXuPg1YFcyXch8wv4d133X3WcFjRZn1iIhEblRVJZ+6bDKPvtjIKzv6PuzEhh1v8YOnX+PDsycyd8bYECs8XrlBsAC4P5i+H7ip1Ebu/gywr8z3EhFJjM9fO40zhlXwv558pU9XELV1dPKln77MyOGVfO0vZ/ZDhceUGwTj3L0JIHjuS2QtMbOXg/ZRydYSgJktNrN6M6tvbm7ua70iIgPijOEV3HHdNJ7dspenXjm1Iardnf+xfAOvNB3gGzedz8jhlf1UZd5Jg8DMfmVm60s8FoTw/ncB5wCzgCbgn3va0N2XuXudu9dVV1eH8NYiIv3rU5dP5pzqKr65YiOt7b2/cc33Vm3mgefe4G+vOYf554/vxwrzThoE7v4+dz+/xOMJYJeZTQAInnefypu7+y5373D3TuCHwJy+/CFEROKoIpvhqx+Yyda9Lfyol/creOC5N/iXX23mo5fU8OX3T+/fAgPltoaWA4uC6UXAE6eycyFEAjcD63vaVkQkia6ZXs1V08bwr6s28+ah1hNuu3LDTr76+DrmTq/mnz58AWY2IDWWGwTfAuaZ2WZgXjCPmZ1lZl1XAJnZg8CzwHQzazSz24JV3zazdWb2MjAX+EKZ9YiIxIqZ8dUPzOTg0Xb+8Yn1JcOgtb2TB59/g88/+CIX1ozkzk/NpiI7cF/zsrDHwxgIdXV1Xl9fH3UZIiK99p2Vm/j+rxsYWpHh43W13HblVKpHDOGh57fxw99uoemtI8yqHcm9f3Mpo6v65+Swma1x97p3LFcQiIgMjE073+ae327h8bXb6eh0qobkePtIO5dNHc1/m3suV08b06/tIAWBiEhM7DpwhPv+sJWm/Ye59YrJXDJ59IC8b09BkBuQdxcRkS7jTh/Kf58/I+oyuiQzCDZtgmuuiboKEZFBQaOPioikXDKPCKZPh6efjroKEZFk6eFEtI4IRERSTkEgIpJyCgIRkZRTEIiIpJyCQEQk5RQEIiIppyAQEUk5BYGISMolctA5M2sGXu/j7mOAPSGW0x9UY3iSUKdqDIdqPLnJ7v6Oe/0mMgjKYWb1pUbfixPVGJ4k1Kkaw6Ea+06tIRGRlFMQiIikXBqDYFnUBfSCagxPEupUjeFQjX2UunMEIiJyvDQeEYiISBEFgYhIyqUqCMxsvpltMrMGM1sadT0AZnavme02s/VFy0ab2VNmtjl4HhVxjbVm9msz22hmG8zs7+JWp5kNNbPnzeyloMb/Gbcai2rNmtmLZvZkHGs0s61mts7M1ppZfUxrHGlmj5jZn4L/L6+IYY3Tg59h4XHAzO6IW52QoiAwsyxwJ3ADMBO4xcxmRlsVAPcB87stWwqscvdpwKpgPkrtwN+7+3nA5cDtwc8uTnUeBa5194uAWcB8M7uceNVY8HfAxqL5ONY4191nFV3zHrcavwf8wt1nABeR/3nGqkZ33xT8DGcBlwAtwGPErE4A3D0VD+AKYGXR/FeAr0RdV1DLFGB90fwmYEIwPQHYFHWN3ep9ApgX1zqB4cALwGVxqxGoIf+P/1rgyTj+fQNbgTHdlsWmRuB04M8EF7vEscYSNV8P/D6udabmiACYCGwrmm8MlsXROHdvAgiex0ZcTxczmwJcDDxHzOoMWi5rgd3AU+4euxqBfwG+DHQWLYtbjQ780szWmNniYFmcajwbaAb+LWix3WNmVTGrsbuFwIPBdOzqTFMQlLprs66dPQVmdhrwM+AOdz8QdT3duXuH5w/Da4A5ZnZ+xCUdx8z+Etjt7muiruUk3uvus8m3UW83s6ujLqibHDAbuMvdLwYOEYf2Sg/MrBL4EPDTqGvpSZqCoBGoLZqvAXZEVMvJ7DKzCQDB8+6I68HMKsiHwI/d/dFgcezqBHD3/cDT5M+9xKnG9wIfMrOtwEPAtWb2H8SrRtx9R/C8m3xPew7xqrERaAyO+AAeIR8Mcaqx2A3AC+6+K5iPXZ1pCoLVwDQzmxok9EJgecQ19WQ5sCiYXkS+Jx8ZMzPg/wEb3f3/FK2KTZ1mVm1mI4PpYcD7gD8Roxrd/SvuXuPuU8j///df7v5XxKhGM6sysxGFafK97fXEqEZ33wlsM7PpwaLrgFeIUY3d3MKxthDEsc6oT1IM8AmbG4FXgdeAf4i6nqCmB4EmoI38bzq3AWeSP6G4OXgeHXGNV5Jvo70MrA0eN8apTuBC4MWgxvXA14LlsamxW73XcOxkcWxqJN9/fyl4bCj8O4lTjUE9s4D64O/7cWBU3GoM6hwO7AXOKFoWuzo1xISISMqlqTUkIiIlKAhERFJOQSAiknIKAhGRlFMQiIiknIJARCTlFAQiIin3/wHmwO0My1O9QQAAAABJRU5ErkJggg=="
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('py38': conda)"
        },
        "interpreter": {
            "hash": "941818c099361a5754e1da29e083e866870a71bc7f8f7df3a8fd48bd98ec7877"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}